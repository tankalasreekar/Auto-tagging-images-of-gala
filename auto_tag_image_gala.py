# -*- coding: utf-8 -*-
"""auto_tag_image_gala.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qmx_KNftm4dps8nDXft0KzWGJL419fL_
"""

!ls

!unzip 9d34462453e311ea.zip

"""# Importing Libraries"""

import os
import cv2
import numpy as np
import pandas as pd
import seaborn as sns
from tqdm import tqdm
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow
from sklearn.preprocessing import LabelEncoder

from tensorflow import keras
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Conv2D, MaxPooling2D 
from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense ,BatchNormalization

"""# Loading data"""

train_csv_path = 'dataset/train.csv'
test_csv_path = 'dataset/test.csv'

train = pd.read_csv(train_csv_path)
test = pd.read_csv(test_csv_path)

train.Class.value_counts()

labels = list(train.Class.unique())
labelencoder = LabelEncoder()
train.iloc[:,1] = labelencoder.fit_transform(train.iloc[:,1])
train['Class'] = train.Class.astype(str).str.get_dummies().values.tolist()
train.head()

def load_train_data(IMG_SIZE):
  train_img_path='dataset/Train Images'
  j = 0
  train_img=[]
  train_label=[]
  for i in tqdm(train['Image']):
      final_path=os.path.join(train_img_path,i)
      img=cv2.imread(final_path)
      img=cv2.resize(img,(IMG_SIZE,IMG_SIZE))
      train_img.append(img)
      train_label.append(train['Class'][j])
      j+=1
  return np.array(train_img),np.array(train_label)

def load_test_data(IMG_SIZE):
  test_img_path='dataset/Test Images'
  test_img=[]
  for i in tqdm(test['Image']):
      final_path=os.path.join(test_img_path,i)
      img=cv2.imread(final_path)
      img=cv2.resize(img,(IMG_SIZE,IMG_SIZE))
      test_img.append(img)
  return np.array(test_img)

train_images , train_labels = load_train_data(224)

test_images = load_test_data(224)

"""# A look at the images"""

plt.figure(figsize = (20,10))
columns = 5
for i in range(columns):
  plt.subplot(columns/columns +1, columns,i+1)
  plt.imshow(np.array(train_images[i]))

print(np.shape(train_images[0]))
cv2_imshow(train_images[0])

print(np.shape(train_images[3]))
cv2_imshow(train_images[2])

"""# Simple CNN Model"""

def gala_model():
  model = Sequential()
  model.add(Conv2D(32,(3,3),activation = 'relu',input_shape = (224,224,3)))
  model.add(MaxPooling2D((2,2)))
  model.add(Dropout(0.3))
  model.add(Conv2D(64,(3,3),activation = 'relu'))
  model.add(MaxPooling2D((2,2)))
  model.add(Conv2D(128,(3,3),activation = 'relu'))
  model.add(Dropout(0.3))
  model.add(Flatten())
  model.add(Dense(128,activation = 'relu'))
  model.add(Dense(4,activation = 'softmax'))
  model.compile(loss='categorical_crossentropy', optimizer='Adagrad', metrics=['accuracy'])
  return model

sns.set()

def make_plots(history,epochs = 10):

  fig , ax = plt.subplots(1,2,figsize = (15,5))

  # summarize history for accuracy

  sns.lineplot(x = list(range(1,epochs+1)) , y = history.history['accuracy'],ax = ax[0])
  sns.lineplot(x = list(range(1,epochs+1)) , y = history.history['val_accuracy'], ax = ax[0])
  ax[0].set_title('model accuracy')
  ax[0].set_ylabel('accuracy')
  ax[0].set_xlabel('epoch')
  ax[0].legend(['train', 'test'])

  # summarize history for loss

  sns.lineplot(x = list(range(1,epochs+1)) , y = history.history['loss'],ax = ax[1])
  sns.lineplot(x = list(range(1,epochs+1)) , y = history.history['val_loss'], ax= ax[1])
  ax[1].set_title('model loss')
  ax[1].set_ylabel('loss')
  ax[1].set_xlabel('epoch')
  ax[1].legend(['train', 'test'])

model = gala_model()
epochs = 15
history = model.fit(train_images, train_labels ,batch_size=64, epochs=epochs, validation_split=0.1)

make_plots(history , epochs)

"""# CNN with BatchNorm"""

def gala_model2():
  model = Sequential()
  model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(224, 224, 3)))
  model.add(MaxPooling2D(pool_size=(2,2)))
  model.add(BatchNormalization())
  model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2,2)))
  model.add(BatchNormalization())
  model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2,2)))
  model.add(BatchNormalization())
  model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2,2)))
  model.add(BatchNormalization())
  model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2,2)))
  model.add(BatchNormalization())
  model.add(Dropout(0.2))
  model.add(Flatten())
  model.add(Dense(128, activation='relu'))
  #model.add(Dropout(0.3))
  model.add(Dense(4, activation = 'softmax'))
  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model

model = gala_model2()

epochs = 15
gala_model2_history = model.fit(train_images,train_labels,batch_size = 64,epochs = epochs, verbose = 1, validation_split = 0.1)

make_plots(gala_model2_history,epochs = epochs)

"""# VGG19 Network"""

from keras.applications import VGG19
from keras.layers import *
from keras.models import Sequential
from tensorflow.keras.callbacks import ReduceLROnPlateau

vgg19 = VGG19(weights='imagenet', include_top=False, input_shape = (224, 224, 3),pooling='avg')
vgg19.trainable = False

model = Sequential([
  vgg19, 
  Dense(1024, activation='relu'),
  Dropout(0.5),
  Dense(256, activation='relu'),
  Dense(4, activation='softmax'),
])

reduce_learning_rate = ReduceLROnPlateau(monitor='loss',factor=0.1,patience=2,cooldown=2,min_lr=0.00001,verbose=1)

callbacks = [reduce_learning_rate]

model.compile( optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

epochs = 20
vgg19_history = model.fit(train_images,train_labels, batch_size=64, epochs=epochs,callbacks=callbacks,validation_split=0.1)

make_plots(vgg19_history,epochs)

"""# ResNet50"""

from keras.applications import ResNet50
from keras.layers import *
from keras.models import Sequential
from tensorflow.keras.callbacks import ReduceLROnPlateau

resnet = ResNet50(weights='imagenet', include_top=False, input_shape = (224, 224, 3),pooling='avg')
resnet.trainable = False

model = Sequential([
  resnet, 
  Dense(1024, activation='relu'),
  Dropout(0.5),
  Dense(256, activation='relu'),
  Dense(4, activation='softmax'),
])

reduce_learning_rate = ReduceLROnPlateau(monitor='loss',factor=0.1,patience=2,cooldown=2,min_lr=0.00001,verbose=1)

callbacks = [reduce_learning_rate]

model.compile( optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

epochs = 20
resnet_history = model.fit(train_images,train_labels, batch_size=64, epochs=epochs,callbacks=callbacks,validation_split=0.1)

make_plots(resnet_history,epochs)

"""# Mobile Net"""

from keras.applications import MobileNetV2
from keras.layers import *
from keras.models import Sequential
from tensorflow.keras.callbacks import ReduceLROnPlateau

mobile = MobileNetV2(weights='imagenet', include_top=False, input_shape = (224, 224, 3),pooling='avg')
mobile.trainable = False

model = Sequential([
  mobile, 
  Dense(1024, activation='relu'),
  Dropout(0.5),
  Dense(256, activation='relu'),
  Dense(4, activation='softmax'),
])

reduce_learning_rate = ReduceLROnPlateau(monitor='loss',factor=0.1,patience=2,cooldown=2,min_lr=0.00001,verbose=1)

callbacks = [reduce_learning_rate]

model.compile( optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

epochs = 20
mobile_history = model.fit(train_images,train_labels, batch_size=64, epochs=epochs,callbacks=callbacks,validation_split=0.1)

make_plots(mobile_history,epochs)